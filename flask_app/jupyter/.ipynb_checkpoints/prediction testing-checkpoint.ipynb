{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fcb3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "\n",
    "def pm25_predict(input_lat,input_lng,input_date):\n",
    "\n",
    "\n",
    "\n",
    "    predict_input = pd.DataFrame({'longitude':input_lng,'latitude':input_lat,'date':input_date}, index = [0])\n",
    "\n",
    "    # Convert strings to datetime objects\n",
    "    begin_date_obj = datetime.strptime(input_date, \"%Y-%m-%d\")\n",
    "    end_date_obj = begin_date_obj + timedelta(days=1)\n",
    "\n",
    "    # Convert back to string\n",
    "    end_date = end_date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Set up sqlite\n",
    "    connection = sqlite3.connect('static/data/sensors_readings_2016_present.db')\n",
    "\n",
    "    # Assemble Query\n",
    "    sql_query = \"\"\"\n",
    "    SELECT sensor_id, pm2\n",
    "    FROM sensors_readings\n",
    "    WHERE date(date) BETWEEN ? AND ?\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query\n",
    "    df = pd.read_sql_query(sql_query, connection, params=(input_date, end_date))\n",
    "\n",
    "    connection.close()\n",
    "#\n",
    "#\n",
    "    # merge with sensor cateogires\n",
    "    df_cat = pd.read_csv('static/data/sensor_categories.csv')\n",
    "    df = df.merge(df_cat, on = 'sensor_id')\n",
    "\n",
    "    df = df[['county','pm2']]\n",
    "    df = df.groupby('county').mean()\n",
    "    df.reset_index(inplace = True)\n",
    "#\n",
    "#\n",
    "#\n",
    "    url = 'static/data/centroid_prep.csv'\n",
    "    predict_input = predict_input.merge(pd.read_csv(url), on = ['latitude','longitude'])\n",
    "\n",
    "\n",
    "    row = predict_input.iloc[0]  # Access the first row\n",
    "    # Get the column names of the last three columns where the value is True\n",
    "    true_column = row.index[-3:][row.iloc[-3:] == True]\n",
    "#\n",
    "#import logging\n",
    "\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    # Then, in your pm25_predict function or anywhere else:\n",
    "    logging.debug('Debug message: %s', 'This is a debug messagexxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "    predict_input['avg_pm2'] = df.loc[df.county == list(true_column)[0].split('_')[1]].pm2.values[0]\n",
    "    logging.basicConfig(predict_input)\n",
    "    logging.debug('Debug message: %s', 'This is a debug messagexxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "    predict_input = predict_input[['longitude', 'latitude', 'date','category_blue', 'category_green',\n",
    "           'category_orange', 'category_red', 'county_Davis County',\n",
    "           'county_Salt Lake County', 'county_Weber County', 'avg_pm2']]\n",
    "    predict_input['month'] = begin_date_obj.month\n",
    "\n",
    "\n",
    "    # Encode Month\n",
    "    predict_input['month_1'] = False if begin_date_obj.month != 1 else True\n",
    "    predict_input['month_2'] = False if begin_date_obj.month != 2 else True\n",
    "    predict_input['month_3'] = False if begin_date_obj.month != 3 else True\n",
    "    predict_input['month_4'] = False if begin_date_obj.month != 4 else True\n",
    "    predict_input['month_5'] = False if begin_date_obj.month != 5 else True\n",
    "    predict_input['month_6'] = False if begin_date_obj.month != 6 else True\n",
    "    predict_input['month_7'] = False if begin_date_obj.month != 7 else True\n",
    "    predict_input['month_8'] = False if begin_date_obj.month != 8 else True\n",
    "    predict_input['month_9'] = False if begin_date_obj.month != 9 else True\n",
    "    predict_input['month_10'] = False if begin_date_obj.month != 10 else True\n",
    "    predict_input['month_11'] = False if begin_date_obj.month != 11 else True\n",
    "    predict_input['month_12'] = False if begin_date_obj.month != 12 else True\n",
    "\n",
    "\n",
    "    # Load the preprocessor\n",
    "    preprocessor = load('static/data/preprocessor.joblib')\n",
    "\n",
    "    # Now you can transform new data using the loaded preprocessor\n",
    "    X_new_transformed = preprocessor.transform(predict_input)\n",
    "    \n",
    "    a = 10\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35debf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=40.757601113297994\n",
    "lng= = -111.89746840953491\n",
    "the_date = '2020-01-01'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (capstonev)",
   "language": "python",
   "name": "capstonev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
