{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f141ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_info(the_date):\n",
    "\n",
    "    dfx = pd.DataFrame({'latitude':[40.6442],'longitude':[111.9522]},\\\n",
    "             index=  ['Salt Lake County'])\n",
    "\n",
    "    start_date = datetime.strptime(the_date, '%Y-%m-%d')\n",
    "    end_date = start_date + timedelta(days=10)\n",
    "\n",
    "    #final_date = datetime.datetime.strptime(\"2024-03-20\", '%Y-%m-%d')\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": list(dfx.latitude.values),\n",
    "        \"longitude\": list(dfx.longitude.values),\n",
    "        \"start_date\": datetime.strftime(start_date, '%Y-%m-%d'),\n",
    "        \"end_date\": datetime.strftime(start_date, '%Y-%m-%d'),\n",
    "        \"daily\": [\"wind_speed_10m_max\", \"wind_gusts_10m_max\", \"wind_direction_10m_dominant\",],\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"wind_speed_unit\": \"mph\",\n",
    "        \"timezone\": \"America/Denver\"\n",
    "    }\n",
    "    responses = requests.get(url, params=params)\n",
    "    return responses.json()['daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caf90a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "#responses = wind_info(the_date='2023-06-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b20ad98e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'responses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponses\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'responses' is not defined"
     ]
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d69ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta  # Import both datetime and timedelta\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def wind_info(the_date):\n",
    "    dfx = pd.DataFrame({'latitude': [40.6442], 'longitude': [111.9522]}, index=['Salt Lake County'])\n",
    "    \n",
    "    start_date = datetime.strptime(the_date, '%Y-%m-%d')\n",
    "    end_date = start_date + timedelta(days=10)\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": dfx.iloc[0].latitude,  # Use scalar values for latitude and longitude\n",
    "        \"longitude\": dfx.iloc[0].longitude,\n",
    "        \"start_date\": start_date.strftime('%Y-%m-%d'),\n",
    "        \"end_date\": end_date.strftime('%Y-%m-%d'),\n",
    "        \"daily\": [\"wind_speed_10m_max\", \"wind_gusts_10m_max\", \"wind_direction_10m_dominant\"],\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"wind_speed_unit\": \"mph\",\n",
    "        \"timezone\": \"America/Denver\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    daily_data = response.json().get('daily', {})  # ensures'daily' key exists and has a default value\n",
    "    return daily_data\n",
    "\n",
    "def find_nearest_sensor_pm_value(latitude, longitude, df, pm_type='pm2'):\n",
    "    coords = df[['latitude', 'longitude']].values\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(coords)\n",
    "    distances, indices = nbrs.kneighbors([[latitude, longitude]])\n",
    "    nearest_index = indices[0][0]\n",
    "    nearest_pm_value = df.iloc[nearest_index][pm_type]\n",
    "    return nearest_pm_value\n",
    "\n",
    "def pm25_predict(input_lat, input_lng, input_date, cluster_labels):\n",
    "    url_base = '../static/data/'\n",
    "\n",
    "    input_lng = round(input_lng, 5)\n",
    "    input_lat = round(input_lat, 5)\n",
    "\n",
    "    predict_input = pd.DataFrame({'longitude': [input_lng], 'latitude': [input_lat], 'date': [input_date]})\n",
    "\n",
    "    begin_date_obj = datetime.strptime(input_date, \"%Y-%m-%d\")\n",
    "    end_date_obj = begin_date_obj + timedelta(days=1)\n",
    "    end_date = end_date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    connection = sqlite3.connect(f'{url_base}sensors_readings_2016_present.db')\n",
    "    sql_query = \"\"\"\n",
    "    SELECT sensor_id, pm2, pm10, latitude, longitude\n",
    "    FROM sensors_readings\n",
    "    WHERE date(date) BETWEEN ? AND ?\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql_query, connection, params=(input_date, end_date))\n",
    "    connection.close()\n",
    "\n",
    "    df_cat = pd.read_csv(f'{url_base}sensor_categories.csv')\n",
    "    df = df.merge(df_cat, on='sensor_id')\n",
    "    nearest_pm2_5_value = find_nearest_sensor_pm_value(input_lat, input_lng, df, 'pm2')\n",
    "    nearest_pm10_value = find_nearest_sensor_pm_value(input_lat, input_lng, df, 'pm10')\n",
    "\n",
    "    url = f'{url_base}centroids_merge.csv'\n",
    "    temp = pd.read_csv(url)\n",
    "    temp['latitude'] = temp['latitude'].round(5)\n",
    "    temp['longitude'] = temp['longitude'].round(5)\n",
    "\n",
    "    predict_input = predict_input.merge(temp, on=['latitude', 'longitude'])\n",
    "    predict_input['month'] = begin_date_obj.month\n",
    "    # 'county' column in predict_input for the following operations to work\n",
    "    predict_input['avg_pm2'] = df.loc[df['county'] == predict_input['county'].iloc[0], 'pm2'].values[0]\n",
    "    predict_input['avg_pm10'] = df.loc[df['county'] == predict_input['county'].iloc[0], 'pm10'].values[0]\n",
    "\n",
    "    category_map = {'red': 1, 'orange': 2, 'green': 3, 'blue': 4}\n",
    "    county_map = {'Salt Lake County': 1, 'Weber County': 2, 'Davis County': 3}\n",
    "    predict_input['county_encoded'] = predict_input['county'].map(county_map)\n",
    "    predict_input['category_encoded'] = predict_input['category'].map(category_map)\n",
    "\n",
    "    df = predict_input[['latitude', 'longitude', 'avg_pm10', 'avg_pm2', 'county_encoded', 'category_encoded', 'month']]\n",
    "    df['cluster_labels'] = cluster_labels\n",
    "    df['nearest_pm2_5'] = nearest_pm2_5_value\n",
    "    df['nearest_pm10'] = nearest_pm10_value\n",
    "    print(input_date)\n",
    "    responses = wind_info(input_date)\n",
    "    # contains the expected keys before assignment\n",
    "    df['wind_direction_10m_dominant'] = responses.get('wind_direction_10m_dominant', [np.nan])[0]\n",
    "    df['wind_gusts_10m_max'] = responses.get('wind_gusts_10m_max', [np.nan])[0]\n",
    "    df['wind_speed_10m_max'] = responses.get('wind_speed_10m_max', [np.nan])[0]\n",
    "\n",
    "    preprocessor = load(f'{url_base}preprocessor.joblib')\n",
    "    X_new_transformed = preprocessor.transform(df)\n",
    "\n",
    "    return X_new_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4b9648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/515260482.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cluster_labels'] = cluster_labels\n",
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/515260482.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nearest_pm2_5'] = nearest_pm2_5_value\n",
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/515260482.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nearest_pm10'] = nearest_pm10_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-08\n"
     ]
    }
   ],
   "source": [
    "lat=40.74591050575336\n",
    "lng=-111.89694078602857\n",
    "the_date='2020-12-08'\n",
    "df = pm25_predict(lat,lng,the_date,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40b4b14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x46 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4382d6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'nearest_pm2_5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, mean_absolute_error\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Absolute Error (MAE):\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_absolute_error(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnearest_pm2_5\u001b[49m, df\u001b[38;5;241m.\u001b[39mpm2))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error (MSE):\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_squared_error(df\u001b[38;5;241m.\u001b[39mnearest_pm2_5, df\u001b[38;5;241m.\u001b[39mpm2))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoot Mean Squared Error (RMSE):\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_squared_error(df\u001b[38;5;241m.\u001b[39mnearest_pm2_5, df\u001b[38;5;241m.\u001b[39mpm2, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'nearest_pm2_5'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(df.nearest_pm2_5, df.pm2))\n",
    "print(\"Mean Squared Error (MSE):\", mean_squared_error(df.nearest_pm2_5, df.pm2))\n",
    "print(\"Root Mean Squared Error (RMSE):\", mean_squared_error(df.nearest_pm2_5, df.pm2, squared=False))\n",
    "print(\"R-squared Score:\", r2_score(df.nearest_pm2_5, df.pm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c589645",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat= 41.14339925293028\n",
    "lng=  -112.029677791514445\n",
    "the_date = '2023-04-01'\n",
    "\n",
    "#41.118140\t-112.031425\t62.482979\t57.820677\t3\t1\t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "340d1ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "8c348318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "pm25_predict(lat,lng,the_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6c695c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf = pd.read_csv('../static/data/centroids_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c1ad27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../static/data/centroids_data.csv').to_json('../static/data/centroids_data.json', orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24262961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-111.89747"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(lng,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e20c2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = '../static/data/centroid_prep.csv'\n",
    "temp_centroid = pd.read_csv(url)\n",
    "temp_centroid['latitude'] = temp_centroid['latitude'].round(5)\n",
    "temp_centroid['longitude'] = temp_centroid['longitude'].round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c5545cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>Tract</th>\n",
       "      <th>Low</th>\n",
       "      <th>Lowmod</th>\n",
       "      <th>Lowmod_pct</th>\n",
       "      <th>geometry</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>County_encoded</th>\n",
       "      <th>category_encoded</th>\n",
       "      <th>category_blue</th>\n",
       "      <th>category_green</th>\n",
       "      <th>category_orange</th>\n",
       "      <th>category_red</th>\n",
       "      <th>county_Davis County</th>\n",
       "      <th>county_Salt Lake County</th>\n",
       "      <th>county_Weber County</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>199060</td>\n",
       "      <td>490111251021</td>\n",
       "      <td>125102</td>\n",
       "      <td>120</td>\n",
       "      <td>340</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>POINT (-111.88080951152304 41.08032456289652)</td>\n",
       "      <td>-111.880810</td>\n",
       "      <td>41.080325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>199061</td>\n",
       "      <td>490111251022</td>\n",
       "      <td>125102</td>\n",
       "      <td>245</td>\n",
       "      <td>490</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>POINT (-111.88003663259194 41.04248386241919)</td>\n",
       "      <td>-111.880037</td>\n",
       "      <td>41.042484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>199062</td>\n",
       "      <td>490111251031</td>\n",
       "      <td>125103</td>\n",
       "      <td>370</td>\n",
       "      <td>850</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>POINT (-111.9563088264819 41.13919426676789)</td>\n",
       "      <td>-111.956309</td>\n",
       "      <td>41.139194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>199063</td>\n",
       "      <td>490111251032</td>\n",
       "      <td>125103</td>\n",
       "      <td>430</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>POINT (-111.94339340147886 41.11547671683034)</td>\n",
       "      <td>-111.943393</td>\n",
       "      <td>41.115477</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>199064</td>\n",
       "      <td>490111251041</td>\n",
       "      <td>125104</td>\n",
       "      <td>165</td>\n",
       "      <td>475</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>POINT (-111.91575298025643 41.12877405887183)</td>\n",
       "      <td>-111.915753</td>\n",
       "      <td>41.128774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>907</td>\n",
       "      <td>200607</td>\n",
       "      <td>490572112012</td>\n",
       "      <td>211201</td>\n",
       "      <td>70</td>\n",
       "      <td>170</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>POINT (-111.92049976396636 41.15200853107149)</td>\n",
       "      <td>-111.920500</td>\n",
       "      <td>41.152009</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>908</td>\n",
       "      <td>200608</td>\n",
       "      <td>490572112013</td>\n",
       "      <td>211201</td>\n",
       "      <td>365</td>\n",
       "      <td>975</td>\n",
       "      <td>0.4194</td>\n",
       "      <td>POINT (-111.93262761353571 41.156133092177804)</td>\n",
       "      <td>-111.932628</td>\n",
       "      <td>41.156133</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>909</td>\n",
       "      <td>200609</td>\n",
       "      <td>490572112021</td>\n",
       "      <td>211202</td>\n",
       "      <td>115</td>\n",
       "      <td>270</td>\n",
       "      <td>0.3354</td>\n",
       "      <td>POINT (-111.96410356104677 41.16503488421328)</td>\n",
       "      <td>-111.964104</td>\n",
       "      <td>41.165035</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>910</td>\n",
       "      <td>200610</td>\n",
       "      <td>490572112022</td>\n",
       "      <td>211202</td>\n",
       "      <td>620</td>\n",
       "      <td>1710</td>\n",
       "      <td>0.3963</td>\n",
       "      <td>POINT (-111.95158835880763 41.15407118264731)</td>\n",
       "      <td>-111.951588</td>\n",
       "      <td>41.154071</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>911</td>\n",
       "      <td>200611</td>\n",
       "      <td>490572112023</td>\n",
       "      <td>211202</td>\n",
       "      <td>135</td>\n",
       "      <td>360</td>\n",
       "      <td>0.2637</td>\n",
       "      <td>POINT (-111.9382183835146 41.14257349659315)</td>\n",
       "      <td>-111.938218</td>\n",
       "      <td>41.142573</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  OBJECTID         GEOID   Tract  Low  Lowmod  Lowmod_pct  \\\n",
       "0             0    199060  490111251021  125102  120     340      0.1833   \n",
       "1             1    199061  490111251022  125102  245     490      0.1892   \n",
       "2             2    199062  490111251031  125103  370     850      0.3131   \n",
       "3             3    199063  490111251032  125103  430    1000      0.4264   \n",
       "4             4    199064  490111251041  125104  165     475      0.1967   \n",
       "..          ...       ...           ...     ...  ...     ...         ...   \n",
       "907         907    200607  490572112012  211201   70     170      0.1560   \n",
       "908         908    200608  490572112013  211201  365     975      0.4194   \n",
       "909         909    200609  490572112021  211202  115     270      0.3354   \n",
       "910         910    200610  490572112022  211202  620    1710      0.3963   \n",
       "911         911    200611  490572112023  211202  135     360      0.2637   \n",
       "\n",
       "                                           geometry   longitude   latitude  \\\n",
       "0     POINT (-111.88080951152304 41.08032456289652) -111.880810  41.080325   \n",
       "1     POINT (-111.88003663259194 41.04248386241919) -111.880037  41.042484   \n",
       "2      POINT (-111.9563088264819 41.13919426676789) -111.956309  41.139194   \n",
       "3     POINT (-111.94339340147886 41.11547671683034) -111.943393  41.115477   \n",
       "4     POINT (-111.91575298025643 41.12877405887183) -111.915753  41.128774   \n",
       "..                                              ...         ...        ...   \n",
       "907   POINT (-111.92049976396636 41.15200853107149) -111.920500  41.152009   \n",
       "908  POINT (-111.93262761353571 41.156133092177804) -111.932628  41.156133   \n",
       "909   POINT (-111.96410356104677 41.16503488421328) -111.964104  41.165035   \n",
       "910   POINT (-111.95158835880763 41.15407118264731) -111.951588  41.154071   \n",
       "911    POINT (-111.9382183835146 41.14257349659315) -111.938218  41.142573   \n",
       "\n",
       "     County_encoded  category_encoded  category_blue  category_green  \\\n",
       "0                 0                 0           True           False   \n",
       "1                 0                 0           True           False   \n",
       "2                 0                 1          False            True   \n",
       "3                 0                 1          False            True   \n",
       "4                 0                 0           True           False   \n",
       "..              ...               ...            ...             ...   \n",
       "907               2                 0           True           False   \n",
       "908               2                 1          False            True   \n",
       "909               2                 1          False            True   \n",
       "910               2                 1          False            True   \n",
       "911               2                 1          False            True   \n",
       "\n",
       "     category_orange  category_red  county_Davis County  \\\n",
       "0              False         False                 True   \n",
       "1              False         False                 True   \n",
       "2              False         False                 True   \n",
       "3              False         False                 True   \n",
       "4              False         False                 True   \n",
       "..               ...           ...                  ...   \n",
       "907            False         False                False   \n",
       "908            False         False                False   \n",
       "909            False         False                False   \n",
       "910            False         False                False   \n",
       "911            False         False                False   \n",
       "\n",
       "     county_Salt Lake County  county_Weber County  \n",
       "0                      False                False  \n",
       "1                      False                False  \n",
       "2                      False                False  \n",
       "3                      False                False  \n",
       "4                      False                False  \n",
       "..                       ...                  ...  \n",
       "907                    False                 True  \n",
       "908                    False                 True  \n",
       "909                    False                 True  \n",
       "910                    False                 True  \n",
       "911                    False                 True  \n",
       "\n",
       "[912 rows x 19 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df8a442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = '../static/data/'\n",
    "connection = sqlite3.connect(f'{url_base}sensors_readings_2016_present.db')\n",
    "sql_query = \"\"\"\n",
    "SELECT date(date) as date\n",
    "FROM sensors_readings\n",
    "order by date(date)asc\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(sql_query, connection)\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9e9698c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271643</th>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271644</th>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271645</th>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271646</th>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271647</th>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271648 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date\n",
       "0       2016-03-16\n",
       "1       2016-03-17\n",
       "2       2016-03-18\n",
       "3       2016-03-19\n",
       "4       2016-03-20\n",
       "...            ...\n",
       "271643  2024-04-10\n",
       "271644  2024-04-10\n",
       "271645  2024-04-10\n",
       "271646  2024-04-10\n",
       "271647  2024-04-10\n",
       "\n",
       "[271648 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "188a5582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>2024-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>2024-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>2024-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>2024-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>2024-03-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2911 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date\n",
       "0     2016-03-16\n",
       "1     2016-03-17\n",
       "2     2016-03-18\n",
       "3     2016-03-19\n",
       "4     2016-03-20\n",
       "...          ...\n",
       "2906  2024-03-04\n",
       "2907  2024-03-05\n",
       "2908  2024-03-06\n",
       "2909  2024-03-07\n",
       "2910  2024-03-08\n",
       "\n",
       "[2911 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../static/data/date_range.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c619b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def return_table(begin_date, end_date,red,orange,green,lightBlue,salt,web,dav,r0,r1,r2,o0,o1,o2,b0,b1,b2,g0,g1,g2):\n",
    "\n",
    "\n",
    "    # Convert strings to datetime objects\n",
    "    begin_date_obj = datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    end_date_obj = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    # Check if dates are the same\n",
    "    if begin_date_obj == end_date_obj:\n",
    "        # Move end_date forward by one day\n",
    "        end_date_obj += timedelta(days=1)\n",
    "\n",
    "        # Convert back to string if needed\n",
    "        end_date = end_date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # Set up sqlite\n",
    "    connection = sqlite3.connect('../static/data/sensors_readings_2016_present.db')\n",
    "    \n",
    "    # Assemble Query\n",
    "    sql_query = \"\"\"\n",
    "    SELECT sensor_id, latitude, longitude, altitude, AVG(pm2) AS avg_pm2, AVG(pm10) AS avg_pm10\n",
    "    FROM sensors_readings\n",
    "    WHERE date(date) BETWEEN ? AND ?\n",
    "    GROUP BY sensor_id, latitude, longitude, altitude\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    df = pd.read_sql_query(sql_query, connection, params=(begin_date, end_date))\n",
    "    \n",
    "    # Join with color categories\n",
    "    df_color = pd.read_csv('../static/data/sensor_categories.csv')\n",
    "    df = pd.merge(df,df_color, on = 'sensor_id')\n",
    "    \n",
    "    selected_counties =[]\n",
    "    if salt == True:\n",
    "        selected_counties.append('Salt Lake County')\n",
    "    if web == True:\n",
    "        selected_counties.append('Weber County')\n",
    "    if dav == True:\n",
    "        selected_counties.append('Davis County')\n",
    "    \n",
    "    df = df.loc[df['county'].isin(selected_counties)]\n",
    "    \n",
    "    df.drop(['county'], axis=1, inplace=True)\n",
    "    # Get category averages\n",
    "    # Step 1: Calculate Sums and Counts\n",
    "    sums = df.groupby('category').sum().reset_index()\n",
    "    counts = df.groupby('category').count().reset_index().rename(columns={'avg_pm2': 'count', 'avg_pm10': 'drop'}).drop('drop', axis=1)\n",
    "\n",
    "    # Add the external counts and sums\n",
    "    if r0 != 0:\n",
    "        sums.loc[sums['category'] == 'red', 'avg_pm2'] += r1\n",
    "        sums.loc[sums['category'] == 'red', 'avg_pm10'] += r2\n",
    "        counts.loc[counts['category'] == 'red', 'count'] += r0\n",
    "    if o0 != 0:\n",
    "        sums.loc[sums['category'] == 'orange', 'avg_pm2'] += o1\n",
    "        sums.loc[sums['category'] == 'orange', 'avg_pm10'] += o2\n",
    "        counts.loc[counts['category'] == 'orange', 'count'] += o0\n",
    "        \n",
    "    if b0 != 0:\n",
    "        sums.loc[sums['category'] == 'blue', 'avg_pm2'] += b1\n",
    "        sums.loc[sums['category'] == 'blue', 'avg_pm10'] += b2\n",
    "        counts.loc[counts['category'] == 'blue', 'count'] += b0\n",
    "        \n",
    "    if g0 != 0:\n",
    "        sums.loc[sums['category'] == 'green', 'avg_pm2'] += g1\n",
    "        sums.loc[sums['category'] == 'green', 'avg_pm10'] += g2\n",
    "        counts.loc[counts['category'] == 'green', 'count'] += g0\n",
    "    \n",
    "\n",
    "    # Step 3: Calculate Averages\n",
    "    averages = sums.copy()\n",
    "    averages['cat_avg_pm2'] = round(sums['avg_pm2'] / counts['count']).astype('int')\n",
    "    averages['cat_avg_pm10'] = round(sums['avg_pm10'] / counts['count']).astype('int')\n",
    "\n",
    "    averages = averages[['category', 'cat_avg_pm2', 'cat_avg_pm10']]\n",
    "    \n",
    "    # Join\n",
    "    \n",
    "    df['avg_pm2'] = round(df['avg_pm2']).astype('int')\n",
    "    df['avg_pm10'] = round(df['avg_pm10']).astype('int')\n",
    "\n",
    "    df = pd.merge(df,averages, on = 'category')\n",
    "    \n",
    "    selected_colors =[]\n",
    "    if red == True:\n",
    "        selected_colors.append('red')\n",
    "    if orange == True:\n",
    "        selected_colors.append('orange')\n",
    "    if green == True:\n",
    "        selected_colors.append('green')\n",
    "    if lightBlue == True:\n",
    "        selected_colors.append('blue')\n",
    "    \n",
    "    df_income_colors = df.loc[df['category'].isin(selected_colors)]\n",
    "    df = pd.merge(df_income_colors,df_color, on = ['sensor_id','category'])\n",
    "    \n",
    "    connection.close()\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def return_county(begin_date, end_date,red,orange,green,lightBlue,salt,web,dav,s0,s1,s2,w0,w1,w2,d0,d1,d2):\n",
    "\n",
    "\n",
    "    # Convert strings to datetime objects\n",
    "    begin_date_obj = datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    end_date_obj = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    # Check if dates are the same\n",
    "    if begin_date_obj == end_date_obj:\n",
    "        # Move end_date forward by one day\n",
    "        end_date_obj += timedelta(days=1)\n",
    "\n",
    "        # Convert back to string if needed\n",
    "        end_date = end_date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Set up sqlite\n",
    "    connection = sqlite3.connect('../static/data/sensors_readings_2016_present.db')\n",
    "    \n",
    "    # Assemble Query\n",
    "    sql_query = \"\"\"\n",
    "    SELECT sensor_id, latitude, longitude, altitude, AVG(pm2) AS avg_pm2, AVG(pm10) AS avg_pm10\n",
    "    FROM sensors_readings\n",
    "    WHERE date(date) BETWEEN ? AND ?\n",
    "    GROUP BY sensor_id, latitude, longitude, altitude\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    df = pd.read_sql_query(sql_query, connection, params=(begin_date, end_date))\n",
    "    \n",
    "    # Join with color categories\n",
    "    df_color = pd.read_csv('../static/data/sensor_categories.csv')\n",
    "    df = pd.merge(df,df_color, on = 'sensor_id')\n",
    "    \n",
    "    selected_colors =[]\n",
    "    if red == True:\n",
    "        selected_colors.append('red')\n",
    "    if orange == True:\n",
    "        selected_colors.append('orange')\n",
    "    if green == True:\n",
    "        selected_colors.append('green')\n",
    "    if lightBlue == True:\n",
    "        selected_colors.append('blue')\n",
    "    \n",
    "    df = df.loc[df['category'].isin(selected_colors)].reset_index()\n",
    "    \n",
    "    df.drop(['category'], axis=1, inplace=True)\n",
    "    # Get category averages\n",
    "    # Step 1: Calculate Sums and Counts\n",
    "    sums = df.groupby('county').sum().reset_index()\n",
    "    counts = df.groupby('county').count().reset_index().rename(columns={'avg_pm2': 'count', 'avg_pm10': 'drop'}).drop('drop', axis=1)\n",
    "\n",
    "    # Add the external counts and sums\n",
    "    if s0 != 0:\n",
    "        sums.loc[sums['county'] == 'Salt Lake County', 'avg_pm2'] += s1\n",
    "        sums.loc[sums['county'] == 'Salt Lake County', 'avg_pm10'] += s2\n",
    "        counts.loc[counts['county'] == 'Salt Lake County', 'count'] += s0\n",
    "    \n",
    "    if w0 != 0:\n",
    "        sums.loc[sums['county'] == 'Weber County', 'avg_pm2'] += w1\n",
    "        sums.loc[sums['county'] == 'Weber County', 'avg_pm10'] += w2\n",
    "        counts.loc[counts['county'] == 'Weber County', 'count'] += w0\n",
    "\n",
    "    if d0 != 0:\n",
    "        sums.loc[sums['county'] == 'Davis County', 'avg_pm2'] += d1\n",
    "        sums.loc[sums['county'] == 'Davis County', 'avg_pm10'] += d2\n",
    "        counts.loc[counts['county'] == 'Davis County', 'count'] += d0\n",
    "\n",
    "    # Step 3: Calculate Averages\n",
    "    averages = sums.copy()\n",
    "    averages['cat_avg_pm2'] = round(sums['avg_pm2'] / counts['count']).astype('int')\n",
    "    averages['cat_avg_pm10'] = round(sums['avg_pm10'] / counts['count']).astype('int')\n",
    "\n",
    "    averages = averages[['county', 'cat_avg_pm2', 'cat_avg_pm10']]\n",
    "    \n",
    "    # Join\n",
    "    \n",
    "    df['avg_pm2'] = round(df['avg_pm2']).astype('int')\n",
    "    df['avg_pm10'] = round(df['avg_pm10']).astype('int')\n",
    "\n",
    "    df = pd.merge(df,averages, on = 'county')\n",
    "         \n",
    "    \n",
    "    selected_counties =[]\n",
    "    if salt == True:\n",
    "        selected_counties.append('Salt Lake County')\n",
    "    if web == True:\n",
    "        selected_counties.append('Weber County')\n",
    "    if dav == True:\n",
    "        selected_counties.append('Davis County')\n",
    "                 \n",
    "    \n",
    "    df = df.loc[df['county'].isin(selected_counties)]\n",
    "    df = pd.merge(df,df_color, on = ['sensor_id','county'])\n",
    "    \n",
    "    \n",
    "    connection.close()\n",
    "    return df\n",
    "    \n",
    "\n",
    "# This will be for linear graph data\n",
    "def sensor_linear(begin_date,end_date, the_sensor):\n",
    "    connection = sqlite3.connect('../static/data/sensors_readings_2016_present.db')\n",
    "    \n",
    "    # Assemble Query\n",
    "    sql_query = \"\"\"\n",
    "    SELECT date(date) as theDate, pm2\n",
    "    FROM sensors_readings\n",
    "    where (date(date) between ? and ?) and (sensor_id = ?)\n",
    "    order by date asc\n",
    "    \"\"\"\n",
    "    \n",
    "    #df = pd.read_sql_query(sql_query, connection, params=(begin_date, end_date))\n",
    "    df = pd.read_sql_query(sql_query, connection, params=(begin_date,end_date,the_sensor))\n",
    "    connection.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "985f12a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreturn_county\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2024-01-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2024-01-03\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 184\u001b[0m, in \u001b[0;36mreturn_county\u001b[0;34m(begin_date, end_date, red, orange, green, lightBlue, salt, web, dav, s0, s1, s2, w0, w1, w2, d0, d1, d2)\u001b[0m\n\u001b[1;32m    180\u001b[0m averages \u001b[38;5;241m=\u001b[39m averages[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounty\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_avg_pm2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_avg_pm10\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Join\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_pm2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg_pm2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_pm10\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_pm10\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    187\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df,averages, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounty\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/capstonev/lib/python3.10/site-packages/pandas/core/generic.py:6640\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6634\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6635\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6636\u001b[0m     ]\n\u001b[1;32m   6638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6639\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6640\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6641\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/capstonev/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/capstonev/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/miniforge3/envs/capstonev/lib/python3.10/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/capstonev/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/capstonev/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/capstonev/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mensure_string_array(\n\u001b[1;32m     97\u001b[0m         arr, skipna\u001b[38;5;241m=\u001b[39mskipna, convert_na_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     )\u001b[38;5;241m.\u001b[39mreshape(shape)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(arr\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating) \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/capstonev/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:145\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(values)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m     )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "return_county('2024-01-01', '2024-01-01',True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,\\\n",
    " True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe45902b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>altitude</th>\n",
       "      <th>pm2</th>\n",
       "      <th>pm10</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77</td>\n",
       "      <td>40.750816</td>\n",
       "      <td>-111.82529</td>\n",
       "      <td>2016-03-16 00:00:00</td>\n",
       "      <td>4870</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.960</td>\n",
       "      <td>2016-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77</td>\n",
       "      <td>40.750816</td>\n",
       "      <td>-111.82529</td>\n",
       "      <td>2016-03-17 00:00:00</td>\n",
       "      <td>4870</td>\n",
       "      <td>1.463</td>\n",
       "      <td>1.718</td>\n",
       "      <td>2016-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>40.750816</td>\n",
       "      <td>-111.82529</td>\n",
       "      <td>2016-03-18 00:00:00</td>\n",
       "      <td>4870</td>\n",
       "      <td>1.758</td>\n",
       "      <td>1.988</td>\n",
       "      <td>2016-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>40.750816</td>\n",
       "      <td>-111.82529</td>\n",
       "      <td>2016-03-19 00:00:00</td>\n",
       "      <td>4870</td>\n",
       "      <td>2.504</td>\n",
       "      <td>2.808</td>\n",
       "      <td>2016-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>40.750816</td>\n",
       "      <td>-111.82529</td>\n",
       "      <td>2016-03-20 00:00:00</td>\n",
       "      <td>4870</td>\n",
       "      <td>2.771</td>\n",
       "      <td>3.127</td>\n",
       "      <td>2016-03-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271643</th>\n",
       "      <td>47171</td>\n",
       "      <td>40.689796</td>\n",
       "      <td>-112.08269</td>\n",
       "      <td>2024-04-10 00:00:00</td>\n",
       "      <td>4473</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.910</td>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271644</th>\n",
       "      <td>46881</td>\n",
       "      <td>40.675575</td>\n",
       "      <td>-112.01961</td>\n",
       "      <td>2024-04-10 00:00:00</td>\n",
       "      <td>4489</td>\n",
       "      <td>5.175</td>\n",
       "      <td>6.675</td>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271645</th>\n",
       "      <td>46875</td>\n",
       "      <td>41.097664</td>\n",
       "      <td>-111.97415</td>\n",
       "      <td>2024-04-10 00:00:00</td>\n",
       "      <td>4627</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.805</td>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271646</th>\n",
       "      <td>77</td>\n",
       "      <td>40.750816</td>\n",
       "      <td>-111.82529</td>\n",
       "      <td>2024-04-10 00:00:00</td>\n",
       "      <td>4870</td>\n",
       "      <td>22.550</td>\n",
       "      <td>22.680</td>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271647</th>\n",
       "      <td>204009</td>\n",
       "      <td>40.593708</td>\n",
       "      <td>-111.89525</td>\n",
       "      <td>2024-04-10 00:00:00</td>\n",
       "      <td>4393</td>\n",
       "      <td>2.730</td>\n",
       "      <td>2.980</td>\n",
       "      <td>2024-04-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271648 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sensor_id   latitude  longitude                 date  altitude  \\\n",
       "0              77  40.750816 -111.82529  2016-03-16 00:00:00      4870   \n",
       "1              77  40.750816 -111.82529  2016-03-17 00:00:00      4870   \n",
       "2              77  40.750816 -111.82529  2016-03-18 00:00:00      4870   \n",
       "3              77  40.750816 -111.82529  2016-03-19 00:00:00      4870   \n",
       "4              77  40.750816 -111.82529  2016-03-20 00:00:00      4870   \n",
       "...           ...        ...        ...                  ...       ...   \n",
       "271643      47171  40.689796 -112.08269  2024-04-10 00:00:00      4473   \n",
       "271644      46881  40.675575 -112.01961  2024-04-10 00:00:00      4489   \n",
       "271645      46875  41.097664 -111.97415  2024-04-10 00:00:00      4627   \n",
       "271646         77  40.750816 -111.82529  2024-04-10 00:00:00      4870   \n",
       "271647     204009  40.593708 -111.89525  2024-04-10 00:00:00      4393   \n",
       "\n",
       "           pm2    pm10        date  \n",
       "0        0.901   0.960  2016-03-16  \n",
       "1        1.463   1.718  2016-03-17  \n",
       "2        1.758   1.988  2016-03-18  \n",
       "3        2.504   2.808  2016-03-19  \n",
       "4        2.771   3.127  2016-03-20  \n",
       "...        ...     ...         ...  \n",
       "271643   0.620   0.910  2024-04-10  \n",
       "271644   5.175   6.675  2024-04-10  \n",
       "271645   0.635   0.805  2024-04-10  \n",
       "271646  22.550  22.680  2024-04-10  \n",
       "271647   2.730   2.980  2024-04-10  \n",
       "\n",
       "[271648 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_base = '../static/data/'\n",
    "connection = sqlite3.connect(f'{url_base}sensors_readings_2016_present.db')\n",
    "sql_query = \"\"\"\n",
    "SELECT *,date(date) as date\n",
    "FROM sensors_readings\n",
    "order by date(date)asc\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(sql_query, connection)\n",
    "connection.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac3f5b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>category</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77</td>\n",
       "      <td>red</td>\n",
       "      <td>Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>443</td>\n",
       "      <td>red</td>\n",
       "      <td>Weber County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>525</td>\n",
       "      <td>green</td>\n",
       "      <td>Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>984</td>\n",
       "      <td>blue</td>\n",
       "      <td>Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>992</td>\n",
       "      <td>green</td>\n",
       "      <td>Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>204009</td>\n",
       "      <td>red</td>\n",
       "      <td>Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>204315</td>\n",
       "      <td>green</td>\n",
       "      <td>Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>207743</td>\n",
       "      <td>blue</td>\n",
       "      <td>Salt Lake County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>208781</td>\n",
       "      <td>green</td>\n",
       "      <td>Weber County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>208783</td>\n",
       "      <td>blue</td>\n",
       "      <td>Weber County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor_id category            county\n",
       "0           77      red  Salt Lake County\n",
       "1          443      red      Weber County\n",
       "2          525    green  Salt Lake County\n",
       "3          984     blue  Salt Lake County\n",
       "4          992    green  Salt Lake County\n",
       "..         ...      ...               ...\n",
       "217     204009      red  Salt Lake County\n",
       "218     204315    green  Salt Lake County\n",
       "219     207743     blue  Salt Lake County\n",
       "220     208781    green      Weber County\n",
       "221     208783     blue      Weber County\n",
       "\n",
       "[222 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../static/data/sensor_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6a011ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_county(begin_date, end_date,red,orange,green,lightBlue,salt,web,dav,s0,s1,s2,w0,w1,w2,d0,d1,d2):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Convert strings to datetime objects\n",
    "    begin_date_obj = datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    end_date_obj = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "\n",
    "    # Check if dates are the same\n",
    "    if begin_date_obj == end_date_obj:\n",
    "        # Move end_date forward by one day\n",
    "        begin_date_obj += timedelta(days=-92)\n",
    "    \n",
    "    # Set up sqlite\n",
    "    connection = sqlite3.connect('../static/data/sensors_readings_2016_present.db')\n",
    "    \n",
    "    # Assemble Query\n",
    "    sql_query = \"\"\"\n",
    "    SELECT sensor_id,latitude, longitude, altitude, pm2, pm10, date(date) as date\n",
    "    FROM sensors_readings\n",
    "    WHERE date(date) BETWEEN ? AND ?\n",
    "    AND pm2 IS NOT NULL\n",
    "    AND pm10 IS NOT NULL\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    df = pd.read_sql_query(sql_query, connection, params=(begin_date, end_date))\n",
    "    \n",
    "    # Join with color categories\n",
    "    df_color = pd.read_csv('../static/data/sensor_categories.csv')\n",
    "    df = pd.merge(df,df_color, on = 'sensor_id')\n",
    "    \n",
    "    selected_counties =[]\n",
    "    if salt == True:\n",
    "        selected_counties.append('Salt Lake County')\n",
    "    if web == True:\n",
    "        selected_counties.append('Weber County')\n",
    "    if dav == True:\n",
    "        selected_counties.append('Davis County')\n",
    "    \n",
    "    df = df.loc[df['county'].isin(selected_counties)]\n",
    "    \n",
    "    df.drop(['county'], axis=1, inplace=True)\n",
    "\n",
    "    selected_colors =[]\n",
    "    if red == True:\n",
    "        selected_colors.append('red')\n",
    "    if orange == True:\n",
    "        selected_colors.append('orange')\n",
    "    if green == True:\n",
    "        selected_colors.append('green')\n",
    "    if lightBlue == True:\n",
    "        selected_colors.append('blue')\n",
    "    \n",
    "    df_income_colors = df.loc[df['category'].isin(selected_colors)]\n",
    "    df = pd.merge(df_income_colors,df_color, on = ['sensor_id','category'])\n",
    "    df= df[['pm2','pm10','category','date']].groupby(['category','date']).mean()\n",
    "    \n",
    "    connection.close()\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "549502d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>pm2</th>\n",
       "      <th>pm10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>31.628145</td>\n",
       "      <td>40.070987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>27.728592</td>\n",
       "      <td>34.863066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>19.847171</td>\n",
       "      <td>24.558987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>30.229053</td>\n",
       "      <td>37.358184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>9.865434</td>\n",
       "      <td>11.156697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blue</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>6.526618</td>\n",
       "      <td>7.207645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>blue</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>1.449171</td>\n",
       "      <td>1.654013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blue</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>3.539921</td>\n",
       "      <td>3.919421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>green</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>37.317047</td>\n",
       "      <td>47.149358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>green</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>31.508481</td>\n",
       "      <td>39.179528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>green</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>25.250991</td>\n",
       "      <td>31.068991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>green</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>27.827142</td>\n",
       "      <td>33.723849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>green</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>9.035283</td>\n",
       "      <td>10.243387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>green</td>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>5.832877</td>\n",
       "      <td>6.543887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>green</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>1.925783</td>\n",
       "      <td>2.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>green</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>4.401802</td>\n",
       "      <td>4.829132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category        date        pm2       pm10\n",
       "0      blue  2024-01-01  31.628145  40.070987\n",
       "1      blue  2024-01-02  27.728592  34.863066\n",
       "2      blue  2024-01-03  19.847171  24.558987\n",
       "3      blue  2024-01-04  30.229053  37.358184\n",
       "4      blue  2024-01-05   9.865434  11.156697\n",
       "5      blue  2024-01-06   6.526618   7.207645\n",
       "6      blue  2024-01-07   1.449171   1.654013\n",
       "7      blue  2024-01-08   3.539921   3.919421\n",
       "8     green  2024-01-01  37.317047  47.149358\n",
       "9     green  2024-01-02  31.508481  39.179528\n",
       "10    green  2024-01-03  25.250991  31.068991\n",
       "11    green  2024-01-04  27.827142  33.723849\n",
       "12    green  2024-01-05   9.035283  10.243387\n",
       "13    green  2024-01-06   5.832877   6.543887\n",
       "14    green  2024-01-07   1.925783   2.212500\n",
       "15    green  2024-01-08   4.401802   4.829132"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_county('2024-01-01', '2024-01-08',False,False,True,True,True,True,False,True,True,True,True,True,True,True,True,\\\n",
    " True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "74af3d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pm2</th>\n",
       "      <th>pm10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Davis County</th>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>33.405392</td>\n",
       "      <td>41.921216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>29.167127</td>\n",
       "      <td>36.119588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>20.444637</td>\n",
       "      <td>24.828402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>30.605637</td>\n",
       "      <td>37.213441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>12.144394</td>\n",
       "      <td>13.993404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>7.454020</td>\n",
       "      <td>8.205882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>1.866635</td>\n",
       "      <td>2.127663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>3.607163</td>\n",
       "      <td>4.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Salt Lake County</th>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>39.056144</td>\n",
       "      <td>50.123136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>33.049762</td>\n",
       "      <td>42.057310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>25.449341</td>\n",
       "      <td>31.905857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>28.623705</td>\n",
       "      <td>35.446673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>9.567488</td>\n",
       "      <td>10.881996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>6.103465</td>\n",
       "      <td>6.828835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>1.963561</td>\n",
       "      <td>2.278635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>4.195712</td>\n",
       "      <td>4.700744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Weber County</th>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>25.652167</td>\n",
       "      <td>30.643433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>20.587500</td>\n",
       "      <td>24.058467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>17.381367</td>\n",
       "      <td>20.097567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>26.756267</td>\n",
       "      <td>31.507067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>8.573433</td>\n",
       "      <td>9.603700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>5.910300</td>\n",
       "      <td>6.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>2.564667</td>\n",
       "      <td>2.835633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>3.682067</td>\n",
       "      <td>4.050867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   pm2       pm10\n",
       "county           date                            \n",
       "Davis County     2024-01-01  33.405392  41.921216\n",
       "                 2024-01-02  29.167127  36.119588\n",
       "                 2024-01-03  20.444637  24.828402\n",
       "                 2024-01-04  30.605637  37.213441\n",
       "                 2024-01-05  12.144394  13.993404\n",
       "                 2024-01-06   7.454020   8.205882\n",
       "                 2024-01-07   1.866635   2.127663\n",
       "                 2024-01-08   3.607163   4.000173\n",
       "Salt Lake County 2024-01-01  39.056144  50.123136\n",
       "                 2024-01-02  33.049762  42.057310\n",
       "                 2024-01-03  25.449341  31.905857\n",
       "                 2024-01-04  28.623705  35.446673\n",
       "                 2024-01-05   9.567488  10.881996\n",
       "                 2024-01-06   6.103465   6.828835\n",
       "                 2024-01-07   1.963561   2.278635\n",
       "                 2024-01-08   4.195712   4.700744\n",
       "Weber County     2024-01-01  25.652167  30.643433\n",
       "                 2024-01-02  20.587500  24.058467\n",
       "                 2024-01-03  17.381367  20.097567\n",
       "                 2024-01-04  26.756267  31.507067\n",
       "                 2024-01-05   8.573433   9.603700\n",
       "                 2024-01-06   5.910300   6.418500\n",
       "                 2024-01-07   2.564667   2.835633\n",
       "                 2024-01-08   3.682067   4.050867"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.groupby(['county','date']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7a13e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta  # Import both datetime and timedelta\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def wind_info(the_date):\n",
    "    dfx = pd.DataFrame({'latitude': [40.6442], 'longitude': [111.9522]}, index=['Salt Lake County'])\n",
    "    \n",
    "    start_date = datetime.strptime(the_date, '%Y-%m-%d')\n",
    "    end_date = start_date + timedelta(days=0)\n",
    "\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": dfx.iloc[0].latitude,  # Use scalar values for latitude and longitude\n",
    "        \"longitude\": dfx.iloc[0].longitude,\n",
    "        \"start_date\": start_date.strftime('%Y-%m-%d'),\n",
    "        \"end_date\": end_date.strftime('%Y-%m-%d'),\n",
    "        \"daily\": [\"wind_speed_10m_max\", \"wind_gusts_10m_max\", \"wind_direction_10m_dominant\"],\n",
    "        \"temperature_unit\": \"fahrenheit\",\n",
    "        \"wind_speed_unit\": \"mph\",\n",
    "        \"timezone\": \"America/Denver\"\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    daily_data = response.json().get('daily', {})  # ensures'daily' key exists and has a default value\n",
    "    return daily_data\n",
    "\n",
    "def find_nearest_sensor_pm_value(latitude, longitude, df, pm_type='pm2'):\n",
    "    coords = df[['latitude', 'longitude']].values\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(coords)\n",
    "    distances, indices = nbrs.kneighbors([[latitude, longitude]])\n",
    "    nearest_index = indices[0][0]\n",
    "    nearest_pm_value = df.iloc[nearest_index][pm_type]\n",
    "    return nearest_pm_value\n",
    "\n",
    "\n",
    "\n",
    "def pm25_predict(input_lat, input_lng, input_date, cluster_labels):\n",
    "    url_base = '../static/data/'\n",
    "\n",
    "    input_lng = round(input_lng, 5)\n",
    "    input_lat = round(input_lat, 5)\n",
    "\n",
    "    predict_input = pd.DataFrame({'longitude': [input_lng], 'latitude': [input_lat], 'date': [input_date]})\n",
    "\n",
    "    begin_date_obj = datetime.strptime(input_date, \"%Y-%m-%d\")\n",
    "    end_date_obj = begin_date_obj + timedelta(days=1)\n",
    "    end_date = end_date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    connection = sqlite3.connect(f'{url_base}sensors_readings_2016_present.db')\n",
    "    sql_query = \"\"\"\n",
    "    SELECT sensor_id, pm2, pm10, latitude, longitude\n",
    "    FROM sensors_readings\n",
    "    WHERE date(date) BETWEEN ? AND ?\n",
    "    AND pm2 IS NOT NULL\n",
    "    AND pm10 IS NOT NULL\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(sql_query, connection, params=(input_date, end_date))\n",
    "    connection.close()\n",
    "\n",
    "    df_cat = pd.read_csv(f'{url_base}sensor_categories.csv')\n",
    "    df = df.merge(df_cat, on='sensor_id')\n",
    "    nearest_pm2_5_value = find_nearest_sensor_pm_value(input_lat, input_lng, df, 'pm2')\n",
    "    nearest_pm10_value = find_nearest_sensor_pm_value(input_lat, input_lng, df, 'pm10')\n",
    "\n",
    "    url = f'{url_base}centroids_merge.csv'\n",
    "    temp = pd.read_csv(url)\n",
    "    temp['latitude'] = temp['latitude'].round(5)\n",
    "    temp['longitude'] = temp['longitude'].round(5)\n",
    "\n",
    "    predict_input = predict_input.merge(temp, on=['latitude', 'longitude'])\n",
    "    predict_input['month'] = begin_date_obj.month\n",
    "    # 'county' column in predict_input for the following operations to work\n",
    "    predict_input['avg_pm2'] = df.loc[df['county'] == predict_input['county'].iloc[0], 'pm2'].values[0]\n",
    "    predict_input['avg_pm10'] = df.loc[df['county'] == predict_input['county'].iloc[0], 'pm10'].values[0]\n",
    "\n",
    "    category_map = {'red': 1, 'orange': 2, 'green': 3, 'blue': 4}\n",
    "    county_map = {'Salt Lake County': 1, 'Weber County': 2, 'Davis County': 3}\n",
    "    predict_input['county_encoded'] = predict_input['county'].map(county_map)\n",
    "    predict_input['category_encoded'] = predict_input['category'].map(category_map)\n",
    "\n",
    "    df = predict_input[['latitude', 'longitude', 'avg_pm10', 'avg_pm2', 'county_encoded', 'category_encoded', 'month']]\n",
    "    df['cluster_labels'] = cluster_labels\n",
    "    df['nearest_pm2_5'] = nearest_pm2_5_value\n",
    "    df['nearest_pm10'] = nearest_pm10_value\n",
    "    print(input_date)\n",
    "    responses = wind_info(input_date)\n",
    "    print(responses)\n",
    "    # contains the expected keys before assignment\n",
    "    df['wind_direction_10m_dominant'] = responses.get('wind_direction_10m_dominant', [np.nan])[0]\n",
    "    df['wind_gusts_10m_max'] = responses.get('wind_gusts_10m_max', [np.nan])[0]\n",
    "    df['wind_speed_10m_max'] = responses.get('wind_speed_10m_max', [np.nan])[0]\n",
    "    print(nearest_pm2_5_value)\n",
    "    preprocessor = load(f'{url_base}preprocessor.joblib')\n",
    "    X_new_transformed = preprocessor.transform(df)\n",
    "    scaler = load(f'{url_base}preprocessorMinMax.joblib')\n",
    "    X_new_transformed = scaler.transform(X_new_transformed)\n",
    "    return X_new_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "576d2137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/469470331.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cluster_labels'] = cluster_labels\n",
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/469470331.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nearest_pm2_5'] = nearest_pm2_5_value\n",
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/469470331.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nearest_pm10'] = nearest_pm10_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': ['2020-01-01', '2020-01-02'], 'wind_speed_10m_max': [5.8, 5.3], 'wind_gusts_10m_max': [10.3, 9.6], 'wind_direction_10m_dominant': [308, 212]}\n",
      "18.9085\n",
      "2024-04-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/469470331.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['cluster_labels'] = cluster_labels\n",
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/469470331.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nearest_pm2_5'] = nearest_pm2_5_value\n",
      "/var/folders/kn/v0dr_8xn1qj15xgwlhdyfzph0000gn/T/ipykernel_6204/469470331.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['nearest_pm10'] = nearest_pm10_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': ['2024-04-09', '2024-04-10'], 'wind_speed_10m_max': [19.3, 18.0], 'wind_gusts_10m_max': [34.7, 33.1], 'wind_direction_10m_dominant': [233, None]}\n",
      "2.205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from joblib import load\n",
    "tensor = pm25_predict(lat,lng,theDate,mapCat)\n",
    "model_pm25 = load_model('../static/data/nnn_model_1_pm_25wind_image.h5')\n",
    "#model_pm10 = load_model('static/data/nnn_model_1_pm_10wind_image.h5')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "tensor = pm25_predict(lat, lng, the_date,cluster_labels)\n",
    "\n",
    "Xpm25 = model_pm25.predict(tensor)\n",
    "#Xpm25 = np.round(np.expm1(Xpm25)[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d7741279",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=40.77587214115332\n",
    "lng=-111.90495337371152\n",
    "the_date='2024-04-10'\n",
    "cluster_labels=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d0da4268",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpm25 = np.round(np.expm1(Xpm25)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "875ab3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xpm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "89cb3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "    start_date = datetime.strptime(the_date, '%Y-%m-%d')\n",
    "    end_date = start_date + timedelta(days=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "202cc63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 4, 9, 0, 0)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86002c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (capstonev)",
   "language": "python",
   "name": "capstonev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
